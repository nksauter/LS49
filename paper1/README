Table 1:  Production of 100,000 simulated images on cori.lbl.gov/haswell
sbatch the following file:

#!/bin/bash -l

#SBATCH -q premium    # premium queue 
#SBATCH -N 120        # Use 5% of nodes 
#SBATCH -t 15:00:00   # wall clock time limit
#SBATCH -J haswell     
#SBATCH -L SCRATCH    # job requires SCRATCH files
#SBATCH -C haswell        
#SBATCH -A            # allocation
#SBATCH -o slurm%N_%j.out
#SBATCH -e slurm%N_%j.err
#SBATCH --mail-user=
#SBATCH --mail-type=ALL

# starts off in ${WORK}/HASWELL1
# -n, tasks to run; -N number of nodes; -c cpus per task;
# n = N x tasks_per_node (should be 8 tasks per node for Haswell)

export OMP_NUM_THREADS=8
export OMP_PLACES=threads
export OMP_PROC_BIND=true

srun -n 960 -c 8 --cpu_bind=cores libtbx.python ../modules/LS49/sim/step6_batch.py

Figures 5,6.

Basic data integration with restraints, Method 2:

   Parameters using the old dials (with new dials, need to add this: profile.gaussian_rs.centroid_definition=com )

mpirun -n 64 dials.stills_process_mpi mp.glob=../HASWELL1/step6_MPIbatch_*.img.gz threshold.dispersion.gain=1.00 filter.min_spot_size=2 indexing.stills.refine_candidates_with_known_symmetry=True indexing.known_symmetry.unit_cell=67.200,59.800,47.200,90.00,110.30,90.00 indexing.known_symmetry.space_group=C2 integration.debug.output=True integration.debug.separate_files=False mp.method=mpi ../all.eff

with ../all.eff:
refinement {
  parameterisation {
    crystal {
      unit_cell {
        restraints {
          tie_to_target {
            values=67.200,59.800,47.200,90.00,110.30,90.00
            sigmas=0.002,0.002,0.002,0.0,0.0034,0.0
          }
        }
      }
    }
  }
}
Total time 19714 sec (5.5 hrs). 99982 integrated.

double-check the indexing/integration solution:
dials.image_viewer idx-step6_MPIbatch_001234.img_integrated_experiments.json idx-step6_MPIbatch_001234.img_integrated.pickle

dials.lbl.gov,step6_MPIbatch_011872.img,2019-04-11T21:06Z46.402,stop,indexing_failed_71
dials.lbl.gov,step6_MPIbatch_067876.img,2019-04-11T21:23Z17.389,stop,indexing_failed_101
dials.lbl.gov,step6_MPIbatch_016011.img,2019-04-11T21:46Z40.204,stop,indexing_failed_97
dials.lbl.gov,step6_MPIbatch_080645.img,2019-04-11T21:47Z59.641,stop,indexing_failed_86
dials.lbl.gov,step6_MPIbatch_063612.img,2019-04-11T21:57Z46.491,stop,indexing_failed_110
dials.lbl.gov,step6_MPIbatch_003090.img,2019-04-11T22:20Z09.828,stop,indexing_failed_87
dials.lbl.gov,step6_MPIbatch_065325.img,2019-04-11T22:21Z59.957,stop,indexing_failed_94
dials.lbl.gov,step6_MPIbatch_046911.img,2019-04-11T22:26Z08.195,stop,indexing_failed_85
dials.lbl.gov,step6_MPIbatch_088899.img,2019-04-11T22:54Z36.974,stop,indexing_failed_85
dials.lbl.gov,step6_MPIbatch_028326.img,2019-04-11T23:51Z44.261,stop,indexing_failed_83
dials.lbl.gov,step6_MPIbatch_071184.img,2019-04-12T00:00Z28.904,stop,indexing_failed_63
dials.lbl.gov,step6_MPIbatch_065124.img,2019-04-12T00:30Z48.031,stop,indexing_failed_94
dials.lbl.gov,step6_MPIbatch_058294.img,2019-04-12T00:35Z10.438,stop,indexing_failed_96
dials.lbl.gov,step6_MPIbatch_000940.img,2019-04-12T00:46Z02.166,stop,indexing_failed_109
dials.lbl.gov,step6_MPIbatch_067207.img,2019-04-12T01:13Z07.950,stop,indexing_failed_73
dials.lbl.gov,step6_MPIbatch_077472.img,2019-04-12T01:30Z06.122,stop,indexing_failed_90
dials.lbl.gov,step6_MPIbatch_018143.img,2019-04-12T01:31Z47.983,stop,indexing_failed_85
dials.lbl.gov,step6_MPIbatch_005546.img,2019-04-12T01:31Z52.826,stop,indexing_failed_107
dials.stills_process ../HASWELL1/step6_MPIbatch_XXXXXX.img.gz threshold.dispersion.gain=1.00 filter.min_spot_size=2 indexing.stills.refine_candidates_with_known_symmetry=True indexing.known_symmetry.unit_cell=67.200,59.800,47.200,90.00,110.30,90.00 indexing.known_symmetry.space_group=C2 integration.debug.output=True integration.debug.separate_files=False ../all.eff

Best LSQ fit Scheerer domain size is    821.83 ang
The LSQ full mosaicity is  0.00002 deg; half-mosaicity   0.00001
Couldn't index step6_MPIbatch_067207.img Model has diverged, cannot continue
BEST CANDIDATE:
  rmsd                           : 2.30821521735
Couldn't index step6_MPIbatch_011872.img RMSD too high, 2.308215

[so the failure has something to do with Sauter 2014 mosaicity refinement, LSQ algorithm]

For data integration without restraints, Method 1, the same command is used but without ../all.eff
Total time 18844 sec (5.2 hrs). 99987 integrated.
dials.lbl.gov,step6_MPIbatch_037415.img,2019-04-12T03:19Z27.800,stop,indexing_failed_83
dials.lbl.gov,step6_MPIbatch_011268.img,2019-04-12T03:31Z33.353,stop,indexing_failed_88
dials.lbl.gov,step6_MPIbatch_013591.img,2019-04-12T04:03Z54.719,stop,indexing_failed_88
dials.lbl.gov,step6_MPIbatch_028245.img,2019-04-12T04:14Z33.075,stop,indexing_failed_52
dials.lbl.gov,step6_MPIbatch_024191.img,2019-04-12T04:17Z16.810,stop,indexing_failed_82
dials.lbl.gov,step6_MPIbatch_099612.img,2019-04-12T04:17Z22.647,stop,indexing_failed_109
dials.lbl.gov,step6_MPIbatch_009735.img,2019-04-12T05:14Z04.732,stop,indexing_failed_81
dials.lbl.gov,step6_MPIbatch_048960.img,2019-04-12T05:17Z37.465,stop,indexing_failed_70
dials.lbl.gov,step6_MPIbatch_069223.img,2019-04-12T05:41Z06.236,stop,indexing_failed_85
dials.lbl.gov,step6_MPIbatch_044779.img,2019-04-12T05:42Z26.280,stop,indexing_failed_86
dials.lbl.gov,step6_MPIbatch_090763.img,2019-04-12T07:32Z41.120,stop,indexing_failed_90
dials.lbl.gov,step6_MPIbatch_005546.img,2019-04-12T07:37Z09.471,stop,indexing_failed_107
dials.lbl.gov,step6_MPIbatch_069083.img,2019-04-12T07:43Z52.383,stop,indexing_failed_89
These 13 failures look to be a completely different set.  Therefore, the failures are not intrinsic to the data,
rather they represent bugs in the dials.stills_process

Production of Figure 3:
Panel (a): libtbx.python spectra/energy_results.py # random spectra from LG36, run 209
Panel (b): libtbx.python ML_push/plot_spectra.py # distribution of mean pulse energies histogram
Panel (c): libtbx.python ML_push/plot_spectra.py # cumulative energy profile

Production of Figure 4:
View the reference image and write out fig4_.png with the Actions menu:
dials.image_viewer ls49_big_data/reference/step5_MPIbatch_000000.img.gz
Run the png file through Python Image Library to produce lower-resolution version for publication:
libtbx.python enhance_bragg_spots.py # Use modulus=3 for clearest-looking Bragg spots

Production of Figure 6, continued:
export METHOD2=${SCRATCH}/LS49_step6/integration
export METHOD1=${SCRATCH}/LS49_step6/no_restraints_integration
${SCRATCH}/LS49_step6/HASWELL1/*.gz # 100000 step6 simulated images
For each Method, Figure 6 contains a misorientation histogram, and a cell parameters histogram

Create the digest file
edit the file LS49/work_pre_experiment/step5_ang_misset_to_fine_detail.py
# line 12, image_glob = "${SCRATCH}/LS49_step6/HASWELL1/step6_MPIbatch_0%05d.img.gz"

libtbx.python LS49/work_pre_experiment/step5_ang_misset_to_fine_detail.py fine LS49_step6/no_restraints_integration > method1_to_fine_detail.digest
libtbx.python LS49/work_pre_experiment/step5_ang_misset_to_fine_detail.py fine LS49_step6/integration > method2_to_fine_detail.digest

libtbx.python ../modules/LS49/paper1/Fig6b_plot_angular.py method1_to_fine_detail.digest blue # produces panel (b)
libtbx.python ../modules/LS49/paper1/Fig6b_plot_angular.py method2_to_fine_detail.digest orange # produces panel (c)

dials.show ${METHOD2}/idx-step6_MPIbatch_00*.img_integrated_experiments.json|grep "Unit cell" > cellrestrain.10000 # unix glob rejects 100000 files
dials.show ${METHOD1}/idx-step6_MPIbatch_00*.img_integrated_experiments.json|grep "Unit cell" > cellnorestrain.10000
 # edit these *.10000 files to remove one outlier each
libtbx.python LS49/ML_push/plot_cell.py # produces panel (a)
a restrained mean 67.1991794118 sigma 0.00507461290565 on 9996
b restrained mean 59.7991706683 sigma 0.00539737434486 on 9996
c restrained mean 47.1991282373 sigma 0.00601022671342 on 9996
beta restrained mean 110.300378842 sigma 0.0102236715141 on 9996
a unrestrained mean 67.1959848855 sigma 0.0451533389931 on 9997
b unrestrained mean 59.7982948685 sigma 0.0361793402447 on 9997
c unrestrained mean 47.1976181554 sigma 0.0310845998594 on 9997
beta unrestrained mean 110.300558508 sigma 0.0506479468952 on 9997

** Calculation of energy-dependent geometry profiles (Results, paragraph 1) on cori.lbl.gov

1) Input files are taken from the dials.stills_process output (json + pickle). Transfer to cori using bbcp.

The integration directory for step6 images (with restraints, Method 2) contains 699913 files and is 51 GB.
Get the bbcp executable (amd64, rhel60) from http://www.slac.stanford.edu/~abh/bbcp/bin/amd64_rhel60/ for local linux host
bbcp -T "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" /local/path/file "user_name@dtn01.nersc.gov:/remote/path/"
This is much too slow:
../bbcp -v -r -T "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" integration "${USER}@dtn01.nersc.gov:/global/cscratch1/sd/${USER}"
Therefore try to be smarter and just tar up the exact files needed:
cd LS49_step6/
for m in 0 1 2 3 4 5 6 7 8 9 ; do echo ${m};tar cf ${m}.tar integration/*_0${m}*.img_integrated* ;done
../bbcp -v -r -T "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" *.tar "${USER}@dtn01.nersc.gov:/global/cscratch1/sd/${USER}"
On cori, unpack the tar files
for m in 0 1 2 3 4 5 6 7 8 9 ; do echo ${m};tar xvf ${m}.tar ;done

2) Set up a new work directory on cori (but use an existing developer installation)

completely new conda environment:
salloc -A lcls -C knl -N1 -q interactive -t 04:00:00
export WORK=/global/cscratch1/sd/${USER}/proj-paper1
cd ${WORK}
wget https://raw.githubusercontent.com/cctbx/cctbx_project/master/libtbx/auto_build/bootstrap.py --no-check-certificate
python bootstrap.py hot update --builder=dials
cd ${WORK}/modules
git clone https://github.com/nksauter/LS49.git
cd ${WORK}

module load python/2.7-anaconda-5.2
module swap PrgEnv-intel/6.0.4 PrgEnv-gnu
source /global/common/cori/software/python/2.7-anaconda-5.2/etc/profile.d/conda.sh
conda activate KNLapr22

mkdir ${WORK}/build
cd ${WORK}/build
python ../modules/cctbx_project/libtbx/configure.py LS49 prime iota --enable_openmp_if_possible=True --use_conda
source ${WORK}/build/setpaths.sh
make

export OMP_NUM_THREADS=24
export LS49_BIG_DATA=${WORK}/../ls49_big_data
mkdir ${WORK}/xxx; cd ${WORK}/xxx
libtbx.run_tests_parallel module=LS49 nproc=20 # test to make sure regression test runs

2a) Each-time login instructions

export WORK=/global/cscratch1/sd/${USER}/proj-paper1
cd ${WORK}
salloc -A lcls -C knl -N1 -q interactive -t 04:00:00
export WORK=/global/cscratch1/sd/${USER}/proj-paper1
module load python/2.7-anaconda-5.2
module swap PrgEnv-intel/6.0.4 PrgEnv-gnu
source /global/common/cori/software/python/2.7-anaconda-5.2/etc/profile.d/conda.sh
conda activate KNLapr22
source ${WORK}/build/setpaths.sh
export OMP_NUM_THREADS=32
export LS49_BIG_DATA=/global/cscratch1/sd/nksauter/proj-h0918/ls49_big_data
export BOOST_ADAPTBX_FPE_DEFAULT=1
cd ${WORK}

2b) Requirements for working directory:

mkdir abc_coverage # mandatory output-file subdirectory name within the working directory
confirm_P1_range_reduced_intensities_dict.pickle # see elsewhere for instructions
confirm_sfall_P1_7122_amplitudes.pickle # see elsewhere for instructions

2c) sbatch abc_background_slurm.sh

Slightly worried that the geometrical profiles may be calculated based on the ground truth rather than the Method 2 dials-refined model.
Need to look at the code again to confirm.  Findings:
abc_background.py, line 608 calls get_partiality_response() with ground-truth random orientations from the 100,000 simulations
In util_partiality.py, get_partiality_response calls run_sim2smv(), passing the ground truth. (line 470).
The dials-refined orientation is read-in from the json file by post5_ang_misset.get_item(), but at no point is it used by run_sim2smv()!
Problem is fixed: compute the geometrical models using three different model modes: superpower_postrefinement, dials_refine, and coarse_ground_truth

2f) get results back by bbcp
There are 283340 files, 241GB, in three directories
../bbcp -S "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" "${USER}@dtn01.nersc.gov:/global/cscratch1/sd/${USER}/proj-paper1/abc*/" /net/dials/raid1/sauter/paper1

./bbcp -z -P 10 -w 2M -s 10 -S "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" -N io nksauter@dtn01.nersc.gov:'tar -C /global/cscratch1/sd/nksauter/proj-paper1 -cv -O abc_coverage_coarse_ground_truth' 'tar -C /net/dials/raid1/sauter/paper1 -xf -'
--> transfers 5.8 GB in 10 minutes
./bbcp -z -P 10 -s 10 -S "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" -N io nksauter@dtn01.nersc.gov:'tar -C /global/cscratch1/sd/nksauter/proj-paper1 -cv -O abc_coverage_coarse_ground_truth' 'tar -C /net/dials/raid1/sauter/paper1 -xf -'
--> transfers 9.2 GB in 10 minutes, 8.9 GB if -s 10 is removed.

./bbcp -z -P 10 -s 10 -S "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" -N io nksauter@dtn01.nersc.gov:'tar -C /global/cscratch1/sd/nksauter/proj-paper1 -cv -O abc_coverage_coarse_ground_truth' 'tar -C /net/dials/raid1/sauter/paper1 -xf -'
./bbcp -z -P 10 -s 10 -S "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" -N io nksauter@dtn01.nersc.gov:'tar -C /global/cscratch1/sd/nksauter/proj-paper1 -cv -O abc_coverage_superpower_postrefine' 'tar -C /net/dials/raid1/sauter/paper1 -xf -'
./bbcp -z -P 10 -s 10 -S "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" -N io nksauter@dtn01.nersc.gov:'tar -C /global/cscratch1/sd/nksauter/proj-paper1 -cv -O abc_coverage_dials_refine' 'tar -C /net/dials/raid1/sauter/paper1 -xf -'

Tester:
./bbcp -z -P 10 -w 2M -S "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" -N io nksauter@dtn01.nersc.gov:'tar -C /global/cscratch1/sd/nksauter/proj-paper1 -cv -O xxx' 'tar -C /net/dials/raid1/sauter/paper1 -xf -'

2g) Analyze the results for manuscript text
slurm22227706.out; 6.0 hours, 200 knl nodes, 6800 ranks
hard-code abc_coverage_dials_refine
mpirun -c 64 libtbx.python ../modules/LS49/ML_push/shoebox_stats.py N_total=100000
final report 64 ranks, 99982 input images, 81304 refined images with >= 3 spots
final report 405466 shoeboxes, 162000042 pixels, 8244 unique C2 asu Millers

hard-code abc_coverage_coarse_ground_truth
mpirun -c 64 libtbx.python ../modules/LS49/ML_push/shoebox_stats.py N_total=100000
final report 64 ranks, 99982 input images, 81308 refined images with >= 3 spots
final report 405504 shoeboxes, 162011846 pixels, 8244 unique C2 asu Millers

hard-code abc_coverage_superpower_postrefine
mpirun -c 64 libtbx.python ../modules/LS49/ML_push/shoebox_stats.py N_total=100000

final report 64 ranks, 35847 input images, 29148 refined images with >= 3 spots
final report 144901 shoeboxes, 57942206 pixels, 8242 unique C2 asu Millers

June 27, 2019
Method 3 reindexes the dataset.
Before: beam center at -165.165 mm , 165.055 mm
                       -1501.5 px,   1500.5 px
After joint refine 2000: -165.108 mm, 165.111 mm
   idealized to nearest pixel registration:
                       -165.11 mm,   165.11 mm
                       -1501 px,     1501 px

Make a new panel for Figure 6, reflecting the angular missettings after Method 3 integration:
JSON_GLOB=/net/dials/raid1/sauter/LS49_step6/method3/idx*.img_integrated_experiments.json \
IMAGE_GLOB=/net/dials/raid1/sauter/LS49_step6/HASWELL1/step6_MPIbatch_0%05d.img.gz \
libtbx.python ../modules/LS49/work_pre_experiment/step5_ang_misset_to_fine_detail.py fine > method3_to_fine_detail.digest
libtbx.python ../modules/LS49/paper1/Fig6b_plot_angular.py method3_to_fine_detail.digest red
redo with python PLOT_Height=11800
libtbx.python ../modules/LS49/paper1/Fig6b_plot_angular.py method3_to_fine_detail.digest magenta
save figure as method3_plot6c.pdf
method3_to_fine_detail.digest  99979 measurements; rmsd   0.01428 Median is   0.01060 Max is   0.09551

Transfer all the json/pickle files from dials to cori:
create the list of files:
cd /net/dials/raid1/sauter/LS49_step6/
find /net/dials/raid1/sauter/LS49_step6/method3 -type f -name "*_0*.img_integrated*" > tempfilelist
./bbcp -T "ssh -x -a -oFallBackToRsh=no %I -l %U %H /usr/common/usg/bin/bbcp" -N io 'tar -C /net/dials/raid1/sauter/LS49_step6/ -T /net/dials/raid1/sauter/LS49_step6/tempfilelist -cv -O method3' 'nksauter@dtn01.nersc.gov:tar -x --strip-components=5 -C /global/cscratch1/sd/nksauter'
this is the transfer of 200,000 small files, 38 GB, in 25 minutes.

Get abc_coverage from method 3 integration results:
abc_background_slurm_method3.sh:
#!/bin/bash -l
#SBATCH -q premium
#SBATCH -N 100
#SBATCH -t 36:00:00
#SBATCH -J my_job
#SBATCH -L SCRATCH
#SBATCH -C knl
#SBATCH -A lcls
#SBATCH -o slurm%j.out
#SBATCH -e slurm%j.err
export OMP_NUM_THREADS=8
export JSON_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json
export PICKLE_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated.pickle
export IMAGE_GLOB=/global/cscratch1/sd/nksauter/proj-h0918/HASWELL1/step6_MPIbatch_0%05d.img.gz
export USE_POSTREFINE=False
export MODEL_MODE=dials_refine # "superpower_postrefine" | "dials_refine" | "coarse_ground_truth"
srun -n 3400 -c 8 libtbx.python ../modules/LS49/work2_for_aca_lsq/abc_background.py
...results in slurm22643713.out, took 6.74 wall hours

Report out the stats for the dials refine abc_coverage:
JSON_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json \
PICKLE_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated.pickle \
USE_POSTREFINE=False MODEL_MODE=dials_refine \
srun -n 64 -c 4 libtbx.python ../modules/LS49/ML_push/shoebox_stats.py N_total=100000
final report 64 ranks, 99979 input images, 67936 refined images with >= 3 spots
final report 305780 shoeboxes, 106629575 pixels, 8241 unique C2 asu Millers
Comment:  it is unknown why the method 3 fit leads to far fewer refined images with >=3 spots.

slurm_method3_test1.sh:
#!/bin/bash -l
#SBATCH -q premium
#SBATCH -N 40
#SBATCH -t 08:00:00
#SBATCH -J my_job
#SBATCH -L SCRATCH
#SBATCH -C knl
#SBATCH -A lcls
#SBATCH -o slurm%j.out
#SBATCH -e slurm%j.err
export NRANK=64
export JSON_GLOB=/global/cscratch1/sd/nksauter/integration/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json
export PICKLE_GLOB=/global/cscratch1/sd/nksauter/integration/idx-step6_MPIbatch_0%05d.img_integrated.pickle
export USE_POSTREFINE=False
export MODEL_MODE=dials_refine
export ABC_GLOB=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_dials_refine/abcX%06d.pickle
# number of nodes (40) * 272 (knl) / c-stride(8) = number of ranks (1360)
# ground truth
srun -n 1360 -c 8 libtbx.python ../modules/LS49/ML_push/macrocycle_refinery.py \
starting_model.preset.FE1=Fe_oxidized_model starting_model.preset.FE2=Fe_reduced_model N_total=32000 \
LLG_evaluator.enable_plot=False LLG_evaluator.plot_interpolation=True \
LLG_evaluator.max_calls=24 \
LLG_evaluator.title=ox_red_32k > ox_red_32k.out 2>&1
convert -delay 6 -loop 0 ox_red_32k*.png ox_red_32k.gif
this time around the MPI seems to be working

JSON_GLOB=/global/cscratch1/sd/nksauter/integration/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json \
PICKLE_GLOB=/global/cscratch1/sd/nksauter/integration/idx-step6_MPIbatch_0%05d.img_integrated.pickle \
USE_POSTREFINE=False \
MODEL_MODE=dials_refine \
ABC_GLOB=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_dials_refine/abcX%06d.pickle \
libtbx.python ../modules/LS49/ML_push/replot.py \
starting_model.preset.FE1=Fe_oxidized_model starting_model.preset.FE2=Fe_reduced_model N_total=32000 \
LLG_evaluator.enable_plot=True LLG_evaluator.plot_interpolation=True \
LLG_evaluator.max_calls=24 \
LLG_evaluator.title=ox_red_32k

sbatch abc_background_slurm_method3_cgt.sh # provide a new abc_coverage_coarse_ground_truth, based on todays code with method3 integration results.
This will be the ground truth control.
Report out the stats for the dials refine abc_coverage:
JSON_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json \
PICKLE_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated.pickle \
USE_POSTREFINE=False MODEL_MODE=coarse_ground_truth \
srun -n 64 -c 4 libtbx.python ../modules/LS49/ML_push/shoebox_stats.py N_total=100000
final report 64 ranks, 99979 input images, 67936 refined images with >= 3 spots
final report 305777 shoeboxes, 106628830 pixels, 8241 unique C2 asu Millers

Jun 29 results:

method 3 + abc_coverage for coarse_grain_truth. abc_background_slurm_method3_cgt.sh --> slurm22658690.out
Followed by ox_red (ground truth) starting model for fp/fdp: slurm_method3_test3_cgt_gt.sh --> ox_red_32k_cgt_gt.out (had a bug in the script)
Then analysis:
JSON_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json \
PICKLE_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated.pickle \
USE_POSTREFINE=False \
MODEL_MODE=dials_refine \
ABC_GLOB=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_dials_refine/abcX%06d.pickle \
libtbx.python ../modules/LS49/ML_push/replot.py \
starting_model.preset.FE1=Fe_oxidized_model starting_model.preset.FE2=Fe_reduced_model N_total=32000 \
LLG_evaluator.enable_plot=True LLG_evaluator.plot_interpolation=True \
LLG_evaluator.max_calls=24 \
LLG_evaluator.title=ox_red_32k_cgt_gt
result:  the run is stable, but final CC is lower than with step5/method2.  **Should run the full set of controls**,
and possibly up the image count to 50K instead of 32K

July 2, after method 4 calculation:
sbatch slurm_pixel_refinement_method3.sh:
#!/bin/bash -l
#SBATCH -q premium
#SBATCH -N 400
#SBATCH -t 48:00:00  # will be 04:00:00
#SBATCH -J my_job
#SBATCH -L SCRATCH
#SBATCH -C knl
#SBATCH -A lcls
#SBATCH -o slurm%j.out
#SBATCH -e slurm%j.err
export WORK=/global/cscratch1/sd/nksauter/proj-paper1/work
export LS49_BIG_DATA=/global/cscratch1/sd/nksauter/proj-h0918/ls49_big_data
export OMP_NUM_THREADS=16
export BOOST_ADAPTBX_FPE_DEFAULT=1
#export NRANK=64
export JSON_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json
export PICKLE_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated.pickle
export USE_POSTREFINE=False
export MODEL_MODE=dials_refine
export ABC_GLOB_A=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_dials_refine/abcX%06d.pickle
export ABC_GLOB_C=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_coarse_ground_truth/abcX%06d.pickle
export ABC_GLOB=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_dials_refine/abcX%06d.pickle
export ABC_GLOB_PIXEL_REF=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_pixel_refine/abcX%06d.pickle
export IMAGE_GLOB=/global/cscratch1/sd/nksauter/proj-h0918/HASWELL1/step6_MPIbatch_%06d.img.gz
# actually edit nanoBragg_nks to set num threads to 16.
# number of nodes (200) * 272 (knl) / c-stride(16) = number of ranks (3400)
srun -n 6800 -c 16 libtbx.python ../modules/LS49/ML_push/pixel_refinement.py
--> actual use was 30.022 wall hours for slurm22693509.out, producing 67935 refined pickle files in abc_coverage_pixel_refine

Analysis with libtbx.python Fig6e_method4_plot_angular.py: 67935 measurements; rmsd   0.00724 Median is   0.00481 Max is   0.11532 degrees; almost all below 0.02
Unlike the other Fig 6 plots, this one may be against coarse grain truth not fine grain (need to check)
redo it with PLOT_Height=11800 for paper: save as Fig6e.pdf
Count > 0.04 degrees 58 of total 67935
slurm22693509.out  67935 measurements; rmsd   0.00724 Median is   0.00481
Max is   0.11532

Report out the stats for the pixel refinement:
JSON_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json \
PICKLE_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated.pickle \
USE_POSTREFINE=False MODEL_MODE=pixel_refine \
srun -n 64 -c 4 libtbx.python ../modules/LS49/ML_push/shoebox_stats.py N_total=100000
final report 64 ranks, 67935 input images, 67935 refined images with >= 3 spots
final report 305776 shoeboxes, 106628513 pixels, 8241 unique C2 asu Millers

libtbx.python retroanalyze_method4.py: a comparison of spot C.O.M. between method 3 dials refine, and pixel refine method 4.
Analyzing 10000 images: looks like it's centered on 0,0 pixels, with std dev ~0.5 px in horizontal, ~0.25 px in vertical.
This is as expected.
Redo with a histogram plot rather than a 2D scatter:
On 10000 images,
Slow axis stats, mean, stddev= 0.0608944691888 0.231104265791 on N= 30672 spots
Fast axis stats, mean, stddev= -0.146559967076 0.559518961666

submitted test macrocycle refinement starting from Method4, slurm_method4_test1.sh;
cgroup out of memory.  Job killed.  does this mean we have to go to -c 16?

JSON_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated_experiments.json \
PICKLE_GLOB=/global/cscratch1/sd/nksauter/method3/idx-step6_MPIbatch_0%05d.img_integrated.pickle \
USE_POSTREFINE=False \
MODEL_MODE=pixel_refine \
ABC_GLOB=/global/cscratch1/sd/nksauter/proj-paper1/work/abc_coverage_pixel_refine/abcX%06d.pickle \
libtbx.python ../modules/LS49/ML_push/replot.py \
starting_model.preset.FE1=Fe_oxidized_model starting_model.preset.FE2=Fe_reduced_model N_total=50000 \
LLG_evaluator.enable_plot=True LLG_evaluator.plot_interpolation=True \
LLG_evaluator.max_calls=24 \
LLG_evaluator.title=ox_red_50k

libtbx.python retroanalyze_inset2.py
#purports to analyze the last pixel refinement (from Method 3 to Method 4), plotting the optimized angle perturbations
trouble is, there is no way of understanding why they are biased away from zero; because Method 3 is supposed to
be free of the beam-center position bias.
Ang2 stats, mean, stddev= 0.00703017451725 0.0132129049843 on N= 67935
Ang3 stats, mean, stddev= -0.00965262882967 0.0136134690398
could this "bias" be related to the difference between coarse grain & fine grain?
Dials refine fits fine grain orientation, from an Nmosaic=25 simulation.
Yet pixel refinement on the other hand refines the coarse grain orientation with an Nmosaic=50-domain roi manager.
NOT AS ADVERTIZED IN PAPER; NOT 200.

Can I somehow conjure up an rmsd pixel_refinement vs. ground truth abc coverage model?
libtbx.python retroanalyze_inset3.py # Method 4 against Method 3 abc_coverage_coarse_ground_truth
Slow axis stats, mean, stddev= 0.168040492047 0.127537746277 on N= 30666
Fast axis stats, mean, stddev= 0.127656829449 0.226382090227

Paper submitted 7/22/19
Afterward, realize that the first inset should arguably be method 3 vs. ground truth
Therefore change 1 line in the above script to get:
libtbx.python retroanalyze_inset4_post_submission.py # Method 3 against Method 3 abc_coverage_coarse_ground_truth
Slow axis stats, mean, stddev= 0.107610660447 0.239818536269 on N= 35361
Fast axis stats, mean, stddev= 0.272433356376 0.566357300743


libtbx.python make_figure7.py
The rms difference is    1.66023%

7/24/2019:  archive main working directory after paper submission; to /net/dials/raid1/sauter/paper1/
rsync -avz -e ssh nksauter@cori.nersc.gov:/global/cscratch1/sd/nksauter/proj-paper1/work cori_paper1

